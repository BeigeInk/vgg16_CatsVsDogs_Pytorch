{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN_DATA_SIZE = 12500\n",
    "TARGET_DATA_SIZE = 12500\n",
    "RATIO = 0.99\n",
    "EPOCH = 4\n",
    "BATCH_SIZE = 7\n",
    "LOSS_FUNC = nn.BCELoss()\n",
    "LR = 0.0001\n",
    "UPDATE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "INPUT_PATH = os.getcwd()+'\\\\kaggle'\n",
    "OUTPUT_PATH = os.getcwd()+'\\\\kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                transforms.RandomCrop((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):#16\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*7*7,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):#11\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv = nn.Sequential()\n",
    "        i = 1; p = 1\n",
    "        self.conv.add_module('conv-{0}'.format(i),nn.Conv2d(in_channels=  3, out_channels= 64, kernel_size=3, stride=1, padding=1))\n",
    "        self.conv.add_module('ReLU-{0}'.format(i),nn.ReLU());i+=1\n",
    "        self.conv.add_module('LRN',nn.LocalResponseNorm(size=2))\n",
    "        self.conv.add_module('MaxPooling-{0}'.format(p),nn.MaxPool2d(kernel_size=2, stride=2));p+=1   # 224 -> 112\n",
    "        self.conv.add_module('conv-{0}'.format(i),nn.Conv2d(in_channels= 64, out_channels=128, kernel_size=3, stride=1, padding=1))\n",
    "        self.conv.add_module('ReLU-{0}'.format(i),nn.ReLU());i+=1\n",
    "        self.conv.add_module('MaxPooling-{0}'.format(p),nn.MaxPool2d(kernel_size=2, stride=2));p+=1   # 112 -> 56\n",
    "        self.conv.add_module('conv-{0}'.format(i),nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1))\n",
    "        self.conv.add_module('ReLU-{0}'.format(i),nn.ReLU());i+=1\n",
    "        self.conv.add_module('conv-{0}'.format(i),nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1))\n",
    "        self.conv.add_module('ReLU-{0}'.format(i),nn.ReLU());i+=1\n",
    "        self.conv.add_module('MaxPooling-{0}'.format(p),nn.MaxPool2d(kernel_size=2, stride=2));p+=1   # 56 -> 28\n",
    "        self.conv.add_module('conv-{0}'.format(i),nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1))\n",
    "        self.conv.add_module('ReLU-{0}'.format(i),nn.ReLU());i+=1\n",
    "        self.conv.add_module('conv-{0}'.format(i),nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1))\n",
    "        self.conv.add_module('ReLU-{0}'.format(i),nn.ReLU());i+=1\n",
    "        self.conv.add_module('MaxPooling-{0}'.format(p),nn.MaxPool2d(kernel_size=2, stride=2));p+=1   # 28 -> 14\n",
    "        self.conv.add_module('conv-{0}'.format(i),nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1))\n",
    "        self.conv.add_module('ReLU-{0}'.format(i),nn.ReLU());i+=1\n",
    "        self.conv.add_module('conv-{0}'.format(i),nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1))\n",
    "        self.conv.add_module('ReLU-{0}'.format(i),nn.ReLU());i+=1\n",
    "        self.conv.add_module('MaxPooling-{0}'.format(p),nn.MaxPool2d(kernel_size=2, stride=2));p+=1   # 14 -> 7\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*7*7,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(data.Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.data = image_list\n",
    "        self.label = label_list\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        global TRANSFORM\n",
    "        img = Image.open(self.data[index])\n",
    "        data = TRANSFORM(img)\n",
    "        img.close()\n",
    "        return data.cuda(),torch.cuda.FloatTensor([self.label[index]])\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    np.random.seed(998244353)\n",
    "    torch.manual_seed(998244353)\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for i in range(ORIGIN_DATA_SIZE):\n",
    "        image_list.append(INPUT_PATH+\"\\\\train\\\\cat.{0}.jpg\".format(i))\n",
    "        label_list.append(0)\n",
    "        image_list.append(INPUT_PATH+\"\\\\train\\\\dog.{0}.jpg\".format(i))\n",
    "        label_list.append(1)\n",
    "    n = int(ORIGIN_DATA_SIZE*2*RATIO)\n",
    "    train_data = ImageDataset(image_list[:n],label_list[:n])\n",
    "    validate_data = ImageDataset(image_list[n:],label_list[n:])\n",
    "    image_list = []\n",
    "    for i in range(TARGET_DATA_SIZE):\n",
    "        image_list.append(INPUT_PATH+\"\\\\test1\\\\{0}.jpg\".format(i+1))\n",
    "    test_data = ImageDataset(image_list,[0]*TARGET_DATA_SIZE)\n",
    "    # np.random.seed()\n",
    "    # torch.seed()\n",
    "    return train_data,validate_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取数据集完成时间 0.0190 s.\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "PROGRAM_START = time.time()\n",
    "train_data,validate_data,test_data = load()\n",
    "print(\"读取数据集完成时间 %.4f s.\"%(time.time()-PROGRAM_START))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2060'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 #1\\4:\n",
      "batch 1\\3536: Loss = 0.692981\n",
      "batch 101\\3536: Loss = 0.698816\n",
      "batch 201\\3536: Loss = 0.689805\n",
      "batch 301\\3536: Loss = 0.705055\n",
      "batch 401\\3536: Loss = 0.703498\n",
      "batch 501\\3536: Loss = 0.688590\n",
      "batch 601\\3536: Loss = 0.786001\n",
      "batch 701\\3536: Loss = 0.684260\n",
      "batch 801\\3536: Loss = 0.708548\n",
      "batch 901\\3536: Loss = 0.612567\n",
      "batch 1001\\3536: Loss = 0.713203\n",
      "batch 1101\\3536: Loss = 0.650091\n",
      "batch 1201\\3536: Loss = 0.608355\n",
      "batch 1301\\3536: Loss = 0.572527\n",
      "batch 1401\\3536: Loss = 1.070547\n",
      "batch 1501\\3536: Loss = 0.537307\n",
      "batch 1601\\3536: Loss = 0.555364\n",
      "batch 1701\\3536: Loss = 0.502724\n",
      "batch 1801\\3536: Loss = 0.580899\n",
      "batch 1901\\3536: Loss = 0.537893\n",
      "batch 2001\\3536: Loss = 0.892502\n",
      "batch 2101\\3536: Loss = 0.583576\n",
      "batch 2201\\3536: Loss = 0.715771\n",
      "batch 2301\\3536: Loss = 0.591309\n",
      "batch 2401\\3536: Loss = 0.694536\n",
      "batch 2501\\3536: Loss = 0.781403\n",
      "batch 2601\\3536: Loss = 0.333874\n",
      "batch 2701\\3536: Loss = 0.685296\n",
      "batch 2801\\3536: Loss = 0.570198\n",
      "batch 2901\\3536: Loss = 0.512869\n",
      "batch 3001\\3536: Loss = 0.468991\n",
      "batch 3101\\3536: Loss = 0.761126\n",
      "batch 3201\\3536: Loss = 0.764870\n",
      "batch 3301\\3536: Loss = 0.366407\n",
      "batch 3401\\3536: Loss = 0.434444\n",
      "batch 3501\\3536: Loss = 0.647185\n",
      "\t  Validation Loss = 0.589207. Error Rate = 32.000%\n",
      "\t 完成第1轮 耗时 1734.0776 s. 总耗时 = 1736.5193 s.\n",
      "轮次 #2\\4:\n",
      "batch 1\\3536: Loss = 0.371999\n",
      "batch 101\\3536: Loss = 0.773345\n",
      "batch 201\\3536: Loss = 0.334127\n",
      "batch 301\\3536: Loss = 0.381310\n",
      "batch 401\\3536: Loss = 0.248350\n",
      "batch 501\\3536: Loss = 0.539301\n",
      "batch 601\\3536: Loss = 0.422382\n",
      "batch 701\\3536: Loss = 0.587214\n",
      "batch 801\\3536: Loss = 0.320514\n",
      "batch 901\\3536: Loss = 0.388889\n",
      "batch 1001\\3536: Loss = 0.386607\n",
      "batch 1101\\3536: Loss = 0.355947\n",
      "batch 1201\\3536: Loss = 0.478125\n",
      "batch 1301\\3536: Loss = 0.525656\n",
      "batch 1401\\3536: Loss = 0.435717\n",
      "batch 1501\\3536: Loss = 0.259283\n",
      "batch 1601\\3536: Loss = 0.562591\n",
      "batch 1701\\3536: Loss = 0.420250\n",
      "batch 1801\\3536: Loss = 0.815677\n",
      "batch 1901\\3536: Loss = 0.229881\n",
      "batch 2001\\3536: Loss = 0.497810\n",
      "batch 2101\\3536: Loss = 0.338417\n",
      "batch 2201\\3536: Loss = 0.447758\n",
      "batch 2301\\3536: Loss = 0.223904\n",
      "batch 2401\\3536: Loss = 0.373335\n",
      "batch 2501\\3536: Loss = 0.543435\n",
      "batch 2601\\3536: Loss = 0.366392\n",
      "batch 2701\\3536: Loss = 0.521471\n",
      "batch 2801\\3536: Loss = 0.200650\n",
      "batch 2901\\3536: Loss = 0.131952\n",
      "batch 3001\\3536: Loss = 0.313508\n",
      "batch 3101\\3536: Loss = 0.462327\n",
      "batch 3201\\3536: Loss = 0.470707\n",
      "batch 3301\\3536: Loss = 0.464206\n",
      "batch 3401\\3536: Loss = 0.217403\n",
      "batch 3501\\3536: Loss = 0.686623\n",
      "\t  Validation Loss = 0.400495. Error Rate = 17.600%\n",
      "\t 完成第2轮 耗时 656.9564 s. 总耗时 = 2393.4757 s.\n",
      "轮次 #3\\4:\n",
      "batch 1\\3536: Loss = 0.512931\n",
      "batch 101\\3536: Loss = 0.721525\n",
      "batch 201\\3536: Loss = 0.609808\n",
      "batch 301\\3536: Loss = 0.378901\n",
      "batch 401\\3536: Loss = 0.251393\n",
      "batch 501\\3536: Loss = 0.663728\n",
      "batch 601\\3536: Loss = 0.519313\n",
      "batch 701\\3536: Loss = 1.937260\n",
      "batch 801\\3536: Loss = 0.237728\n",
      "batch 901\\3536: Loss = 0.372030\n",
      "batch 1001\\3536: Loss = 0.609294\n",
      "batch 1101\\3536: Loss = 0.244288\n",
      "batch 1201\\3536: Loss = 0.564624\n",
      "batch 1301\\3536: Loss = 0.381257\n",
      "batch 1401\\3536: Loss = 0.895847\n",
      "batch 1501\\3536: Loss = 0.481611\n",
      "batch 1601\\3536: Loss = 0.265144\n",
      "batch 1701\\3536: Loss = 0.336815\n",
      "batch 1801\\3536: Loss = 0.593438\n",
      "batch 1901\\3536: Loss = 0.824948\n",
      "batch 2001\\3536: Loss = 0.527966\n",
      "batch 2101\\3536: Loss = 0.304001\n",
      "batch 2201\\3536: Loss = 0.745772\n",
      "batch 2301\\3536: Loss = 0.592010\n",
      "batch 2401\\3536: Loss = 0.287337\n",
      "batch 2501\\3536: Loss = 0.272433\n",
      "batch 2601\\3536: Loss = 0.247454\n",
      "batch 2701\\3536: Loss = 0.448296\n",
      "batch 2801\\3536: Loss = 0.602566\n",
      "batch 2901\\3536: Loss = 0.441138\n",
      "batch 3001\\3536: Loss = 0.549637\n",
      "batch 3101\\3536: Loss = 0.366092\n",
      "batch 3201\\3536: Loss = 0.445734\n",
      "batch 3301\\3536: Loss = 0.177090\n",
      "batch 3401\\3536: Loss = 0.614246\n",
      "batch 3501\\3536: Loss = 0.462138\n",
      "\t  Validation Loss = 0.399890. Error Rate = 15.600%\n",
      "\t 完成第3轮 耗时 674.2238 s. 总耗时 = 3067.6995 s.\n",
      "轮次 #4\\4:\n",
      "batch 1\\3536: Loss = 0.429728\n",
      "batch 101\\3536: Loss = 0.655424\n",
      "batch 201\\3536: Loss = 0.628686\n",
      "batch 301\\3536: Loss = 0.428010\n",
      "batch 401\\3536: Loss = 0.679430\n",
      "batch 501\\3536: Loss = 0.364581\n",
      "batch 601\\3536: Loss = 0.179680\n",
      "batch 701\\3536: Loss = 0.013304\n",
      "batch 801\\3536: Loss = 0.328190\n",
      "batch 901\\3536: Loss = 0.662832\n",
      "batch 1001\\3536: Loss = 0.104672\n",
      "batch 1101\\3536: Loss = 0.012041\n",
      "batch 1201\\3536: Loss = 0.058668\n",
      "batch 1301\\3536: Loss = 0.156232\n",
      "batch 1401\\3536: Loss = 0.118336\n",
      "batch 1501\\3536: Loss = 0.368334\n",
      "batch 1601\\3536: Loss = 0.351919\n",
      "batch 1701\\3536: Loss = 1.125980\n",
      "batch 1801\\3536: Loss = 0.176240\n",
      "batch 1901\\3536: Loss = 0.309425\n",
      "batch 2001\\3536: Loss = 0.159515\n",
      "batch 2101\\3536: Loss = 0.277355\n",
      "batch 2201\\3536: Loss = 0.119411\n",
      "batch 2301\\3536: Loss = 0.575084\n",
      "batch 2401\\3536: Loss = 0.337314\n",
      "batch 2501\\3536: Loss = 0.504471\n",
      "batch 2601\\3536: Loss = 0.521840\n",
      "batch 2701\\3536: Loss = 0.233502\n",
      "batch 2801\\3536: Loss = 0.240728\n",
      "batch 2901\\3536: Loss = 0.580218\n",
      "batch 3001\\3536: Loss = 0.360176\n",
      "batch 3101\\3536: Loss = 0.282665\n",
      "batch 3201\\3536: Loss = 0.082050\n",
      "batch 3301\\3536: Loss = 0.205016\n",
      "batch 3401\\3536: Loss = 0.767109\n",
      "batch 3501\\3536: Loss = 14.348788\n",
      "\t  Validation Loss = 0.335984. Error Rate = 13.600%\n",
      "\t 完成第4轮 耗时 712.8663 s. 总耗时 = 3780.5658 s.\n"
     ]
    }
   ],
   "source": [
    "net=VGG().cuda()\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=LR, alpha=0.9)\n",
    "LOSS_FUNC.cuda()\n",
    "#加载数据\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "validate_loader = data.DataLoader(validate_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "BATCH = len(train_loader)\n",
    "m = len(validate_loader)\n",
    "\n",
    "loss_list=list()\n",
    "for epoch in range(EPOCH):\n",
    "    EPOCH_START = time.time()\n",
    "    print(\"轮次 #{0}\\\\{1}:\".format(epoch+1,EPOCH))\n",
    "    \n",
    "    for batch,(x,y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        t = net(x)\n",
    "        loss = LOSS_FUNC(t,y)\n",
    "        loss_list.append(loss)\n",
    "        if batch%100==0:\n",
    "            print(\"batch {0}\\\\{1}: \".format(batch+1,BATCH) + \"Loss = %.6f\"%float(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #保存每一epoch的模型\n",
    "    with torch.no_grad():\n",
    "        L = 0.\n",
    "        E = 0.\n",
    "        for batch,(x,y) in enumerate(validate_loader):\n",
    "            t = net(x)\n",
    "            L += float(LOSS_FUNC(t,y))\n",
    "            E += float((float(t[0][0])>0.5)!=y)\n",
    "        print(\"\\t  Validation Loss = %.6f. Error Rate = %.3f%%\"%(L/m,E*100/m))\n",
    "        if((epoch+1)%UPDATE==0):\n",
    "            torch.save(net.state_dict(),OUTPUT_PATH+\"\\\\{0}[{1}]\".format(net.name,epoch+1)+\"-L(%.6f)E(%.3f).pt\"%(L/m,E*100/m))\n",
    "            torch.save(optimizer.state_dict(),OUTPUT_PATH+\"\\\\{0}[{1}]\".format(net.name,epoch+1)+\"-L(%.6f)E(%.3f)-optimizer.pt\"%(L/m,E*100/m))\n",
    "    print(\"\\t 完成第{0}轮\".format(epoch+1)+\" 耗时 %.4f s.\"%(time.time()-EPOCH_START)+\n",
    "          \" 总耗时 = %.4f s.\"%(time.time()-PROGRAM_START))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction = []\n",
    "test_loader = data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "with torch.no_grad():\n",
    "    for i,(x,y) in enumerate(test_loader):\n",
    "        t = net(x)\n",
    "        prediction.append([i+1,float(t[0][0])])\n",
    "submission = pd.DataFrame(prediction)\n",
    "submission.columns = ['id','label']\n",
    "submission.to_csv(\"result.csv\",index=0)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14b313f4130>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def smooth_(list_i):\n",
    "    loss_int=list()\n",
    "    loss_int.append(list_i[0])\n",
    "    for i in range(1,len(list_i)):\n",
    "        loss_int.append(loss_int[-1]*0.99+list_i[i]*0.01)\n",
    "    return loss_int\n",
    "temp=loss_list[::10]\n",
    "k=smooth_(temp)\n",
    "for i in range(10):\n",
    "    k=smooth_(k)\n",
    "\n",
    "plt.plot(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=1000, out_features=1, bias=True)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
